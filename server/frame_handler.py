# server/frame_handler.py

from flask_socketio import emit
import numpy as np
import cv2
import threading

from analyzers.face.detection.tracker import FacePresenceTracker
from analyzers.face.recognition.identifier import identify_face
from analyzers.face.recognition.visualizer import draw_result

# ì „ì—­ ìƒíƒœ ë³€ìˆ˜
face_tracker = FacePresenceTracker(threshold_sec=1.0)
identity_found = False
face_detection_active = False
streaming_active = False
monitor_started = False  # âœ… ì¤‘ë³µ ë°©ì§€

def is_streaming_active():
    return streaming_active

# ğŸ”½ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ì‹œ ê°ì§€ ì¢…ë£Œ ì²˜ë¦¬
def stop_face_detection_due_to_stream_loss():
    global face_detection_active
    face_detection_active = False

    try:
        from app import socketio
        socketio.emit('log_message', "ğŸ›‘ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ìœ¼ë¡œ ì–¼êµ´ ê°ì§€ ì¤‘ë‹¨ë¨", namespace='/admin')
    except Exception as e:
        print("âŒ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ì•Œë¦¼ ì‹¤íŒ¨:", e)

# ğŸ”½ ìŠ¤íŠ¸ë¦¬ë° ê°ì‹œ ìŠ¤ë ˆë“œ ì‹¤í–‰
def monitor_streaming():
    global streaming_active, face_detection_active

    def check_loop():
        while True:
            if face_detection_active:
                streaming_active = False  # ğŸ”„ ë§¤ 2ì´ˆë§ˆë‹¤ ì´ˆê¸°í™”
                threading.Event().wait(2.0)
                if not streaming_active:
                    stop_face_detection_due_to_stream_loss()
            else:
                threading.Event().wait(2.0)

    threading.Thread(target=check_loop, daemon=True).start()

# ğŸ”½ ë“±ë¡ í•¨ìˆ˜
def register_frame_handler(socketio):
    global monitor_started

    @socketio.on('frame', namespace='/client')
    def handle_frame(data):
        global identity_found, face_detection_active, streaming_active

        streaming_active = True  # í”„ë ˆì„ ìˆ˜ì‹  ì¤‘
        if not face_detection_active or identity_found:
            return

        nparr = np.frombuffer(data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        face_tracker.update(frame)

        if face_tracker.is_face_persisted():
            last_frame = face_tracker.get_last_frame()
            identity = identify_face(last_frame)

            if identity:
                identity_found = True
                result_frame = draw_result(last_frame, label=identity)
                cv2.imwrite("final_identified.jpg", result_frame)

                emit('identified', {'user': identity}, namespace='/client')
                emit('log_message', f'âœ… ì–¼êµ´ ì¸ì‹ ì™„ë£Œ: {identity}', namespace='/admin')
            else:
                emit('log_message', "âŒ ì–¼êµ´ì€ ìˆì—ˆì§€ë§Œ ì‹ë³„ ì‹¤íŒ¨", namespace='/admin')
        else:
            emit('log_message', "â³ ì–¼êµ´ ê°ì§€ ì¤‘...", namespace='/admin')

    @socketio.on('start_face_detection', namespace='/admin')
    def start_face_detection():
        global identity_found, face_detection_active
        identity_found = False
        face_detection_active = True
        emit('log_message', "ğŸŸ¢ ì–¼êµ´ ê°ì§€ ì‹œì‘ë¨", namespace='/admin')

    @socketio.on('stop_face_detection', namespace='/admin')
    def stop_face_detection():
        global face_detection_active
        face_detection_active = False
        emit('log_message', "ğŸ”´ ì–¼êµ´ ê°ì§€ ì¤‘ë‹¨ë¨", namespace='/admin')

    # âœ… ìŠ¤íŠ¸ë¦¬ë° ëª¨ë‹ˆí„°ëŠ” ìµœì´ˆ í•œ ë²ˆë§Œ ì‹¤í–‰
    if not monitor_started:
        monitor_streaming()
        monitor_started = True
