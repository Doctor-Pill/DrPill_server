import time
from collections import deque
import numpy as np
import cv2
import threading
from flask_socketio import emit

from app import socketio
from analyzers.face.detection.tracker import FacePresenceTracker
from analyzers.face.recognition.identifier import identify_face_from_bbox
from analyzers.face.recognition.visualizer import draw_result, save_face_clip


# ----------------------------- ìƒíƒœ ë³€ìˆ˜ ----------------------------- #
face_tracker = FacePresenceTracker()
face_detection_active = False
latest_frame = None
frame_lock = threading.Lock()

video_seconds = 6
video_fps = 10
frame_queue = deque(maxlen=video_seconds * video_fps)

# ----------------------------- í”„ë ˆì„ ìˆ˜ì‹  ----------------------------- #
@socketio.on('frame', namespace='/client')
def receive_frame(data):
    global latest_frame
    nparr = np.frombuffer(data, np.uint8)
    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    if frame is None:
        print("âŒ í”„ë ˆì„ ë””ì½”ë”© ì‹¤íŒ¨")
        return

    with frame_lock:
        latest_frame = frame
        frame_queue.append(frame.copy())


# ----------------------------- ì–¼êµ´ ì¸ì‹ ìŠ¤ë ˆë“œ ----------------------------- #
def face_detection_thread():
    global face_detection_active

    while face_detection_active:
        print("ì–¼êµ´ ëŒ€ê¸° ì¤‘")
        with frame_lock:
            if latest_frame is None:
                continue
            frame_copy = latest_frame.copy()

        face_tracker.update(frame_copy)
        bbox = face_tracker.get_last_bbox()
        frame = face_tracker.get_last_frame()

        if bbox is None or frame is None:
            continue

        socketio.emit('log_message', "ğŸ” ì–¼êµ´ ê°ì§€ë¨ â†’ DBì—ì„œ ì–¼êµ´ ì¸ì‹ ì‹œë„ ì¤‘", namespace='/admin')

        identity = identify_face_from_bbox(frame, bbox)

        print(frame, bbox, identity)
        result_frame = draw_result(frame.copy(), label=identity, bbox=bbox)
        cv2.imwrite("final_identified.jpg", result_frame)
        
        
        # ğŸ§  ê²°ê³¼ ë‚˜ì˜¨ ì‹œì ì— ì €ì¥í•  label
        label = identity if identity else "Unknown"

        # âœ… ì–¼êµ´ ì¸ì‹ ê²°ê³¼ë¥¼ logë¡œ ì†¡ì¶œ
        if identity:
            socketio.emit('identified', {'user': identity}, namespace='/client')
            socketio.emit('log_message', f"âœ… ì–¼êµ´ ì¸ì‹ ì™„ë£Œ: {identity}", namespace='/admin')
        else:
            socketio.emit('log_message', "âŒ ë“±ë¡ëœ ì–¼êµ´ ì•„ë‹˜", namespace='/admin')

        # âœ… ì €ì¥: ë§ˆì§€ë§‰ nì´ˆê°„ í”„ë ˆì„ + bbox + label
        save_face_clip(
            frames=list(frame_queue),
            fps=video_fps,
            identity=label,
            filename="face_clip.mp4"
        )

        stop_face_detection()

        break

# ----------------------------- ì‹œì‘ / ì¤‘ë‹¨ ì´ë²¤íŠ¸ ----------------------------- #
@socketio.on('start_face_detection', namespace='/admin')
def start_face_detection():
    global face_detection_active
    face_detection_active = True
    socketio.emit('log_message', "ğŸŸ¢ ì–¼êµ´ ì¸ì‹ í”„ë¡œì„¸ìŠ¤ ì‹œì‘", namespace='/admin')
    socketio.emit('edge_command', {"command": "start_usb_streaming"}, namespace='/admin')
    threading.Thread(target=face_detection_thread, daemon=True).start()

@socketio.on('stop_face_detection', namespace='/admin')
def stop_face_detection():
    global face_detection_active
    face_detection_active = False
    socketio.emit('edge_command', {"command": "stop_streaming"}, namespace='/admin')
    socketio.emit('log_message', "ğŸ”´ ì–¼êµ´ ì¸ì‹ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨", namespace='/admin')
